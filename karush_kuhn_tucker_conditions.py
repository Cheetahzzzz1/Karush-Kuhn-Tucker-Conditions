# -*- coding: utf-8 -*-
"""Karush Kuhn Tucker Conditions.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M7GJNZG4GRroV14wSwdFEMDxoCtyfQfJ
"""

# Question part (a)

import cvxpy as cp
import numpy as np

# Problem data
A = np.array([[4, 0.9, 2],
              [1.3, 0.6, 6]])
b = np.array([1.2, 0.8])
n = 3

# Variables
x = cp.Variable(n)

# Objective: maximize entropy ⇒ maximize -x log x = sum(entr(x))
objective = cp.Maximize(cp.sum(cp.entr(x)))

# Constraints
constraints = [A @ x <= b, cp.sum(x) == 1, x >= 1e-6]

# Solve problem
prob = cp.Problem(objective, constraints)
prob.solve()

print("Optimal x:", x.value)
print("Optimal value:", prob.value)

"""We are given the conditions as:

1.) A =  [[4, 0.9, 2],[1.3, 0.6, 6]]

2.) b = [1.2, 0.8]

3.) n = 3

and we are minimizing:

<sub>i=1</sub>∑<sup>3</sup>x<sub>i</sub>logx<sub>i</sub>

subject to:



*   Ax <= b
*   x<sub>1</sub> + x<sub>2</sub> + x<sub>3</sub> = 1

*   x<sub>i</sub> > 0

Thus we got our x<sup>*</sup> as [0.08766437 0.88666249 0.02567314] and primal optimal solution as 0.41407.

The optimal distribution over the three variables is [0.08766437 0.88666249 0.02567314]

The minimum entropy value is 0.41407.

The vector x<sup>*</sup> represents the maximum entropy solution for the given conditions.
"""

# Question part (b)

import numpy as np
from scipy.optimize import minimize

# Problem data
A = np.array([[4, 0.9, 2],
              [1.3, 0.6, 6]])
b = np.array([1.2, 0.8])
n = 3

# ai are the columns of A
a1 = A[:, 0]
a2 = A[:, 1]
a3 = A[:, 2]

# Define the dual objective function
def dual_objective(lam):
    if np.any(lam < 0):
        return np.inf  # enforce lambda >= 0
    term = np.exp(-a1 @ lam) + np.exp(-a2 @ lam) + np.exp(-a3 @ lam)
    return b @ lam + np.log(term)

# Initial guess
lam0 = np.ones(2)

# Bounds for lambda (non-negative)
bounds = [(0, None), (0, None)]

# Minimize the dual (maximize negative of the objective)
result = minimize(dual_objective, lam0, bounds=bounds)

lambda_star = result.x
dual_opt = -result.fun  # because we minimized the negative of the dual

lambda_star, dual_opt

"""Here we are solving the dual problem which is given by:

max<sub>λ>=0</sub> -b<sup>T</sup>λ - log(∑ e<sup>-a<sub>i</sub><sup>T</sup>λ</sup>) for {i=1 to n}

where a<sub>i</sub> are the columns of A.

The values are:

λ<sup>*</sup> = [0.627165, 0.52816]

dual optimal values = -0.414076

These λ values are dual variables corresponding to inequality constraints.

The dual optimal value matche the primal optimal value which we found in part (a). This confirms strong duality and satisfies Slater's condition.
"""

# Question part (c)

# Assume x_star from earlier
x_star = np.array([0.08766437, 0.88666249, 0.02567314])

# Reuse lambda_star from part (b)
lambda_star = np.array([0.62716765, 0.52816966])

# Compute ∇f0(x) = log(x) + 1
grad_f0 = np.log(x_star) + 1

# Compute A^T @ lambda
AT_lambda = A.T @ lambda_star

# Solve for nu from stationarity condition:
# grad_f0 + A.T @ lambda + nu * 1 = 0  ⇒  nu = - (grad_f0 + A.T @ lambda)_i for any i
# Since 1^T x = 1 is a single constraint, nu is scalar; values should be consistent across i
nu_star = - (grad_f0 + AT_lambda)

# Check consistency of nu values across dimensions
nu_star_mean = np.mean(nu_star)

# Check complementary slackness: lambda_i * (Ax - b)_i ≈ 0
slack = A @ x_star - b
comp_slackness = lambda_star * slack

grad_f0, AT_lambda, nu_star, nu_star_mean, slack, comp_slackness

"""Here from the output we can infer that:

1.) Gradient of f<sub>0</sub>(x) is given by:

grad_f0 in the code, so

∇f<sub>0</sub>(x<sup>*</sup>) = log(x<sup>*</sup>) + 1 = [-1.43423, 0.87970, -2.66230]

These are the partial derivatives of the entropy objective at optimal point x<sup>*</sup>.

2.) A<sup>T</sup>λ<sup>*</sup>:

This is given in the code by AT_lambda

So, A<sup>T</sup>λ<sup>*</sup> = [3.1952, 0.8813, 4.42335]

This is the contribution of the inequality constraints to the Langragian gradient.

3.) Stationarity Check: Solve for ν<sup>*</sup>:

This value is given in the code by nu_star.

So, ν<sup>*</sup> = [-1.76105, -1.76106, -1.76104].

These values are very close to each other. So, we compute the mean of these values which is given by nu_star_mean.

ν<sup>*</sup><sub>mean</sub> = -1.76105.

The stationarity is satisfied , i.e. the components of the KKT stationarity condition are consistent.

4.) Complementary Slackness:

This parameter in the code is given by slack and comp_slackness.

So,

Ax<sup>*</sup> - b = [10<sup>-9</sup>, 1.5 x 10<sup>-8</sup>]

λ<sup>*</sup>(Ax<sup>*</sup> - b) = [6.27 x 10<sup>-10</sup>, 7.922 x 10<sup>-9</sup>].

These values are very close to the value zero, which implies that complementary slackness is satisfied.

This means that:



*   If a constraint is active, then λ<sup>*</sup><sub>i</sub> can be nonzero.
*   If not active, λ<sup>*</sup><sub>i</sub> would be zero.

The Karush-Kuhn-Tucker (KKT) conditions are:



*   Primal Feasibility ( Used a feasible x<sup>*</sup> from part (a))
*   Dual Feasibility (λ<sup>*</sup> >= 0)

*   Stationarity (ν<sup>*</sup> ≃ 0)
*   Complementary slackness (λ<sup>*</sup>(Ax<sup>*</sup> - b) ≃ 0)

So, according to the problem all the KKT conditions are satisfied which confirms that:



*   The primal solution x<sup>*</sup> and dual solution λ<sup>*</sup> are optimal.
*   The problem exhibits strong duality.

*   The mathematical and numerical implementation is correct.
"""